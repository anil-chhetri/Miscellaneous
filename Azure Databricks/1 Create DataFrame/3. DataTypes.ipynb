{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyspark structType and StruckField are used to programmatically specify the schema to the DataFrame and creating complex columns like nested struct, array and map columns. StructType is collection of Structfield's that define column name, column data type, boolean to specify if the field can be nullable or not and metadata.\n",
    "\n",
    "**`pyspark.sql.types.StructType`** class define the structure of the DataFrame. \n",
    "**`pyspark.sql.types.StructField`** class define the columns which includes column name, column type, nullable column and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Dot Net Training\\Miscellaneous\\Azure Databricks\\3. DataTypes.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m StructType, StructField, StringType, IntegerType\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg1\n",
    "\n",
    "data = [\n",
    "    (\"James\", '', 'Smith', \"36636\", \"M\", 3000),\n",
    "    (\"Micheal\", \"Rose\", \"\", \"40288\", \"M\", 4000),\n",
    "    (\"Roboert\", \"\", \"Williams\", \"42114\", \"M\", 4000),\n",
    "    (\"Maria\", \"Anne\", \"jones\", \"39192\", \"F\", 4000),\n",
    "    (\"jen\", \"Mary\", \"Brown\", \"\", \"F\", -1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StructType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Dot Net Training\\Miscellaneous\\Azure Databricks\\3. DataTypes.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=0'>1</a>\u001b[0m Schema \u001b[39m=\u001b[39m StructType([\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=1'>2</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mFirstname\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=2'>3</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mmiddlename\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=3'>4</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mlastname\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=4'>5</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=5'>6</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=6'>7</a>\u001b[0m     StructField(\u001b[39m\"\u001b[39m\u001b[39msalary\u001b[39m\u001b[39m\"\u001b[39m, IntegerType(), \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000005?line=7'>8</a>\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StructType' is not defined"
     ]
    }
   ],
   "source": [
    "Schema = StructType([\n",
    "    StructField(\"Firstname\", StringType(), True),\n",
    "    StructField(\"middlename\", StringType(), True),\n",
    "    StructField(\"lastname\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.createDataFrame(data = data, schema=Schema).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using pandas dataframe to crate spark dataframe. one advantange of doing so it that, even if the values of dict is not uniform we don't any error while creating dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 900.0,\n",
    "        \"customer_from\": datetime.date(2021, 2, 14),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 850.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 21),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 3, 15, 15, 16, 55)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"is_customer\": False,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 10, 17, 45, 30)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"is_customer\": False,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 2, 0, 55, 18)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Dot Net Training\\Miscellaneous\\Azure Databricks\\3. DataTypes.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m Row\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Dot Net Training\\Miscellaneous\\Azure Databricks\\3. DataTypes.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39m#will givve error \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000011?line=1'>2</a>\u001b[0m spark\u001b[39m.\u001b[39mcreateDataframe([Row(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39muser) \u001b[39mfor\u001b[39;00m user \u001b[39min\u001b[39;00m users])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "#will givve error \n",
    "spark.createDataframe([Row(**user) for user in users]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\new folder (2)\\python\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\new folder (2)\\python\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\new folder (2)\\python\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\new folder (2)\\python\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\new folder (2)\\python\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# to fix the error we get help of pandas data frame.\n",
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Dot Net Training\\Miscellaneous\\Azure Databricks\\3. DataTypes.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000013?line=0'>1</a>\u001b[0m spark\u001b[39m.\u001b[39mcreateDataFrame(pd\u001b[39m.\u001b[39mDataFrame(users))\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(pd.DataFrame(users)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Dot Net Training\\Miscellaneous\\Azure Databricks\\3. DataTypes.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dot%20Net%20Training/Miscellaneous/Azure%20Databricks/3.%20DataTypes.ipynb#ch0000014?line=0'>1</a>\u001b[0m spark\u001b[39m.\u001b[39mcreateDataFrame(pd\u001b[39m.\u001b[39mDataFrame(users))\u001b[39m.\u001b[39mprintSchema()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(pd.DataFrame(users)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdc983804108b630f6a4d8a2de07d5c0503f1994d98b4af092e862cbb9507d70"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
