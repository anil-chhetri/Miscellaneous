# Hadoop

## what is hadoop: 
- set of open-source programs and procedures
- Used for processing large amounts of data
- Servers run applications on clusters(A hadoop cluster is a collection of computer working together to perform task)
- hadoop is not database but an ecosystem that handles parallel jobs or processes


## Challenges of hadoop

- processing transaction (lack of random access)
- when work cannot be parallelized
- when there are dependecies in the data 
- low latency data access
- processing lots of small files 
- intensive calculation with little data

To deal with shortcoming of hadoop, new tools like Hive, were build on top of hadoop. hive provided SQL-like query and provided users with strong statistical functions. Pig was popular for its multi query approach to cut down the number of time that the data is scanned. 


## Core components of Hadoop

- HDFS 
- MapReduce
- YARN
- Hadoop Common




